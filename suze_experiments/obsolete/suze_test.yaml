model_name_or_path: allenai/OLMo-2-0425-1B # https://huggingface.co/allenai/OLMo-2-0425-1B
save_dir: /sphinx/u/suzeva/emergent-doordash/
run_name: test-suze
epochs: 1
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 2.0e-5
max_seq_len: 2048
num_proc: 4
logging_steps: 10
eval_steps: 200
num_eval_samples: 128
fp16: false
bf16: true
tf32: true
seed: 42
eval_strategy: "no"
save_strategy: steps
save_steps: 200
save_total_limit: 2
weight_decay: 0.0
warmup_ratio: 0.03
lr_scheduler_type: cosine

# Data: train and eval are MATH
train_dataset: math_train.jsonl
train_split: na
eval_datasets:
#   - DigitalLearningGmbH/MATH-lighteval
eval_splits:
#   - test
cache_dir: /sphinx/u/suzeva/data

# Generation config for callback
max_length: 2048
max_new_tokens: 256
do_sample: false
top_k: 50
top_p: 0.95
temperature: 0.7