dump_dir: /afs/cs.stanford.edu/u/suzeva/emergent-doordash/outputs/sft_math
model_name_or_path: meta-llama/Llama-3.1-8B-Instruct
save_dir: /afs/cs.stanford.edu/u/suzeva/emergent-doordash/checkpoints/sft_math
run_name: sft-math
epochs: 1
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 2.0e-5
max_seq_len: 2048
num_proc: 4
logging_steps: 10
eval_steps: 200
num_eval_samples: 128
fp16: false
bf16: true
tf32: true
seed: 42
eval_strategy: steps
save_strategy: steps
save_steps: 200
save_total_limit: 2
weight_decay: 0.0
warmup_ratio: 0.03
lr_scheduler_type: cosine

# Data: train and eval are MATH
train_dataset: hendrycks/competition_math
train_split: train
eval_datasets:
  - hendrycks/competition_math
eval_splits:
  - test
cache_dir: /afs/cs.stanford.edu/u/suzeva/hf_cache

# Generation config for callback
max_length: 2048
max_new_tokens: 256
do_sample: false
top_k: 50
top_p: 0.95
temperature: 0.7